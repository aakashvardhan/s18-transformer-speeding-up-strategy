{"cells":[{"cell_type":"code","execution_count":null,"id":"14d2b0da","metadata":{"id":"14d2b0da"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n"]},{"cell_type":"code","execution_count":null,"id":"ebeeedf0","metadata":{"id":"ebeeedf0"},"outputs":[],"source":["import os\n","local_dir = 's18-transformer-speeding-up-strategy'\n","repo_url = 'https://github.com/aakashvardhan/s18-transformer-speeding-up-strategy.git'\n","\n","# Check if the local directory already exists\n","if not os.path.exists(local_dir):\n","    # Clone the repository because it does not exist\n","    !git clone --quiet {repo_url}\n","else:\n","    # Change directory to the local repository\n","    %cd {local_dir}\n","    # Pull the latest changes because the repository already exists\n","    !git pull"]},{"cell_type":"code","execution_count":null,"id":"f5156228","metadata":{"id":"f5156228"},"outputs":[],"source":["import sys\n","sys.path.append('/content/s18-transformer-speeding-up-strategy')"]},{"cell_type":"code","execution_count":null,"id":"d629fa71","metadata":{"id":"d629fa71"},"outputs":[],"source":["!pip install -q -r /content/s18-transformer-speeding-up-strategy/requirements.txt"]},{"cell_type":"code","execution_count":null,"id":"8z53PQmTl4og","metadata":{"id":"8z53PQmTl4og"},"outputs":[],"source":["%cd /content/s18-transformer-speeding-up-strategy"]},{"cell_type":"code","execution_count":null,"id":"bf22e721","metadata":{"id":"bf22e721"},"outputs":[],"source":["import os\n","import warnings\n","import random\n","\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.utils.tensorboard import SummaryWriter\n","from torchmetrics.text import BLEUScore, CharErrorRate, WordErrorRate\n","\n","import lightning as L\n","from lightning.pytorch.callbacks import (\n","    EarlyStopping,\n","    LearningRateMonitor,\n","    ModelCheckpoint,\n","    TQDMProgressBar,\n",")\n","from lightning.pytorch.loggers import TensorBoardLogger\n","\n","from config_file import get_config, get_weights_file_path\n","from dataset import LiTDataModule\n","from utils import get_model, greedy_decode"]},{"cell_type":"code","execution_count":null,"id":"c405a818","metadata":{"id":"c405a818"},"outputs":[],"source":["cfg = get_config()\n","# cfg['batch_size'] = 24\n","cfg['num_epochs'] = 18"]},{"cell_type":"code","source":["# Define the directory name\n","directory_name = \"weights\"\n","\n","# Create the directory if it does not exist\n","if not os.path.exists(directory_name):\n","  os.makedirs(directory_name)\n","  print(f\"Directory '{directory_name}' created!\")\n","else:\n","  print(f\"Directory '{directory_name}' already exists.\")"],"metadata":{"id":"3XWGWYSWqc_c"},"id":"3XWGWYSWqc_c","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Clear CUDA cache and set seed\n","torch.cuda.empty_cache()\n","L.seed_everything(42, workers=True)\n","print(\"Seed set to 42...\")"],"metadata":{"id":"VR_XW6EJqk60"},"id":"VR_XW6EJqk60","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the data module\n","datamodule = LiTDataModule(cfg)\n","datamodule.setup()\n","print(\"DataModule initialized...\")\n","tokenizer_src, tokenizer_tgt = datamodule.tokenizer_src, datamodule.tokenizer_tgt\n","train_dataloader = datamodule.train_dataloader()\n","# Initialize TensorBoard logger\n","tb_logger = TensorBoardLogger(\n","    save_dir=os.getcwd(), version=1, name=\"lightning_logs\"\n",")"],"metadata":{"id":"maBLzJ5cq0VY"},"id":"maBLzJ5cq0VY","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the trainer\n","trainer = L.Trainer(\n","            precision=cfg[\"precision\"],\n","            max_epochs=cfg[\"num_epochs\"],\n","            logger=tb_logger,\n","            accelerator=cfg[\"accelerator\"],\n","            devices=\"auto\",\n","            default_root_dir=cfg[\"model_folder\"],\n","            callbacks=[\n","                ModelCheckpoint(\n","                    dirpath=cfg[\"model_folder\"],\n","                    save_top_k=3,\n","                    monitor=\"train_loss_step\",\n","                    mode=\"min\",\n","                    filename=\"model-{epoch:02d}-{train_loss:.4f}\",\n","                    save_last=True,\n","                ),\n","                LearningRateMonitor(logging_interval=\"step\", log_momentum=True),\n","                EarlyStopping(\n","                    monitor=\"train_loss_step\", mode=\"min\", stopping_threshold=1.6\n","                ),\n","                TQDMProgressBar(refresh_rate=10),\n","            ],\n","            gradient_clip_val=0.5,\n","            num_sanity_val_steps=5,\n","            enable_progress_bar=True,\n","            check_val_every_n_epoch=1,\n","            limit_val_batches=2)"],"metadata":{"id":"CwSxatjbrEmO"},"id":"CwSxatjbrEmO","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from main import LTModel\n","# Initialize the model\n","model = LTModel(cfg, tokenizer_src=tokenizer_src, tokenizer_tgt=tokenizer_tgt, train_dataloader=train_dataloader)\n","print(\"Model initialized...\")"],"metadata":{"id":"kbhZ1Ee0rMZu"},"id":"kbhZ1Ee0rMZu","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(cfg[\"one_cycle_best_lr\"])"],"metadata":{"id":"-snQqlCjuMpc"},"id":"-snQqlCjuMpc","execution_count":null,"outputs":[]},{"cell_type":"code","source":[" # Learning rate finder\n","tuner = L.pytorch.tuner.Tuner(trainer)\n","lr_finder = tuner.lr_find(\n","    model, datamodule=datamodule, num_training=trainer.max_epochs, min_lr=1e-5, max_lr=1e-3\n",")\n","print(lr_finder)\n","\n","# Initialize suggested_lr with a default value\n","suggested_lr = model.one_cycle_best_lr\n","\n","if lr_finder:\n","  fig = lr_finder.plot(suggest=True)\n","  fig.show()\n","  suggested_lr = lr_finder.suggestion()\n","  print(f\"Suggested learning rate: {suggested_lr}\")\n","else:\n","  print(\"Learning rate finding did not complete successfully.\")\n","\n","# Set the best learning rate\n","model.one_cycle_best_lr = suggested_lr"],"metadata":{"id":"WFXrJyTjrWfn"},"id":"WFXrJyTjrWfn","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model.one_cycle_best_lr)"],"metadata":{"id":"ZQKNyLsyuqrw"},"id":"ZQKNyLsyuqrw","execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.fit(model=model, datamodule=datamodule)"],"metadata":{"id":"QkiZEIvLrn69"},"id":"QkiZEIvLrn69","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Validate the model\n","trainer.validate(model=model, datamodule=datamodule)\n","print(\"Model Evaluation Done...\")"],"metadata":{"id":"AmI_sirqrplr"},"id":"AmI_sirqrplr","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the model\n","torch.save(model.state_dict(), \"saved_resnet18_model.pth\")\n","print(\"Model saved...\")"],"metadata":{"id":"fwSrIxrqrtnQ"},"id":"fwSrIxrqrtnQ","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"61c39a79","metadata":{"id":"61c39a79"},"outputs":[],"source":["# start tensorboard\n","%load_ext tensorboard\n","%tensorboard --logdir /content/s18-transformer-speeding-up-strategy/lightning_logs"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":8953.048239,"end_time":"2024-06-10T13:30:01.515662","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-06-10T11:00:48.467423","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}